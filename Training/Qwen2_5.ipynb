{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nxE8egDeOCDV"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install --no-deps bitsandbytes accelerate xformers==0.0.29.post3 peft trl==0.15.2 triton cut_cross_entropy unsloth_zoo\n",
        "!pip install sentencepiece protobuf datasets huggingface_hub hf_transfer\n",
        "!pip install --no-deps unsloth"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 540,
          "referenced_widgets": [
            "5d0f87c0c912480598767c62c767722d",
            "e0d71c84c65748e2a24db27485d4d4c2",
            "011509ccdc174441bc44d6e794371282",
            "00beb86dabca414ab9d9174d3382c143",
            "e26c0780637940c794919fe56fbc3ab4",
            "1ec569fbc53b494fbc0095906cdc94b8",
            "10910c2693a74f7589a6d232366f69bd",
            "b8c8288800d94d6c814ca1e73665fa4f",
            "5622573c28ee404792d6570cbcf24e78",
            "5536ffdceb26402385b28e3c759d5eee",
            "d92bd89a2e2241edad02389d15432908",
            "de8380f85d30411bb556020bcfa5cd35",
            "10bfb569ca174b74aa1da485c12c5267",
            "2450e576f7674daeb714a1523d5aa3f4",
            "7ff57d0a220a4d46b2a7bb56134ca120",
            "708d574a882e4da7a825dfb8f3fc8aee",
            "120cdb0a88fd477e824c4bd23ab35e5a",
            "2ce85051c7ed491aafa1956452637eee",
            "92cf39bb6729449687457c37b07a7a45",
            "931be1e9fea343b192578af27fbd7373",
            "8afa3c2a5f294905b876c24f43316f29",
            "ac9d18fc2529422abdfb15e7e4062e60",
            "3537ca78cce54f86a39f9648751b2ec0",
            "4da856d6f310451cb5fa71ca6b8733f0",
            "243b3328f9194ecfa19f50ae076dfe45",
            "133266cae7504d018d044c409972192b",
            "3655e901094a4df59273ce53777cba68",
            "0ebcc25416c6401a9922bd831c97e085",
            "8918c49ba0214066bbd11dac7a5c435d",
            "fd7c697cf5474ec2942c80a2286739e4",
            "025e32b5636c485eaa80d5af74640dd8",
            "2ee7cf4400ba4592ac1f7064066c67e3",
            "6dcf359976334a9a9a6ff7af779d68dd",
            "b182215e45ed4a11a815a93f55931f11",
            "43a3f71f69674f96a9f4a4ecda9f01b5",
            "bc6652d35d884b17941b38645b45c498",
            "9008d04b0cba4a9b9781aed69fcafefd",
            "f029cad8855340788bd57e7f7460a265",
            "3dc5202bd66448e4a2c23c94ef07838c",
            "8d24228f817a450eb172ffcf87610cf8",
            "ab6c32b854d948509da0779580fc519a",
            "27592ea1ba0645d6a858ce55c7dc8ea3",
            "b47f600ff03c48e5bd2fc282a46c6e4c",
            "b94adb7bebc346e58597011fc2539a64",
            "1ced1cbd196e415194772b15e1f8b52b",
            "349d109a8c3848c589d9f1749e151b20",
            "7809926e2c1e4ee6b3176ef833fbe38f",
            "6318f90502884a21a0614c2e58e541a8",
            "901ddc92f166404db765701931c774c9",
            "44821192e89b43afac142c213428efaf",
            "a7247cf4b3a8405facf872469dba8f18",
            "69e93b4d4e5246d0a9963f405340d058",
            "7b923dabe47d4b76ad31158a46179548",
            "35c9250490224550b8e803a922b25c72",
            "01e900dd9462466a84302142de44a3da",
            "ea9bdc7e318e4d058b7096796239ef8e",
            "3c8fae1ee62c433098511eb9e2e8ccb1",
            "bc037e0992e3476991dde8d25843e33f",
            "ff57f3598de240158d09b3adc8e90a0e",
            "a6644bed87cf446db605b4de5f9942dd",
            "f37d7d80bfca4959af5bd14c1efef6fa",
            "afea28e429f2452e923481a824f841f1",
            "64599e56bd994bc48fe0a614a8ae2498",
            "bfc3c47d02954cdda1f31c4a39258369",
            "d9c779e386044058a03df520d5b7720a",
            "c5caa023f46e4741a6de2aa57d8ae2e4",
            "6ec945d3e2b44f39b2603a2cc1ee7e49",
            "1cd15e5aa7154ae0bdd9b4f416f4fc46",
            "919bc2e28374406486f606f06581fe48",
            "62697c332d7d4f5fa50e7a9da9f68002",
            "65fb8324ee144d1fa617535569d47050",
            "dc01503c63424c3e8cf411306d3718b6",
            "15a2af8153804c698c60275e4de1d79e",
            "07736dd48a89443c9340d75584e5e0d9",
            "398438f7a7b94d70a803d02218ac83a0",
            "c9690072b4114d8381266820d87c4262",
            "a18a4cfb912948879b11a1c22718b282",
            "1dd148507d1744fc9659f15d5b5a4d92",
            "3d510e9506884df19b0c704453dca989",
            "4832f8cee53b433baf5f275571f7e8c4",
            "365e72cba3704049a855c8add3414667",
            "faeeb1a6caab4f35b136aff31651e5be",
            "29c415e5f1934be6867f7d059695edb2",
            "372195c923244c51ac748cbc8f5d151e",
            "d1f7fdeb73d341b4a13cfedf350bcc39",
            "c9a9b04f5b274cf2ab041a9ca07d578b",
            "b0f3394f2d784877a4f8ac3674fbb6ca",
            "3b8e1c4a321246339af37a9fcaff4375",
            "7860351cd3e3448792762c271d7b6f89",
            "ea237fe6995f45958a88e6ffda46f54e",
            "e080cef599ca43cab8cd5b80dd7b6012",
            "783dcb00a8e842a2a4f79c05ec3faa5b",
            "1c7a1661499347fb9b3641ed7d1a07d1",
            "f997f844eff840f09e711e1118c4786f",
            "7c58f13b969244419d28e3b5218d7dd8",
            "22ad60def9c5400abe09af223a135a4f",
            "bd8dba2b46ae45d6a438a453cbfd4b61",
            "aec47151418b43db8fcf9ee320323e7d",
            "cbb175b03e48419096dde6265afd5836",
            "1be5b64a6cdf442291cc1bd0881049fe",
            "e35422ef4b2e4876b7715642ccf05e51",
            "b85c2d08abff475a954ac08ac32a7e43",
            "5e2fea90dba54d9b9f5dd4ef330a0d7a",
            "f4f0e47302dc49d59829254c0ecf18d7",
            "cfeeb7b559434df7bc329710a83fab3e",
            "42671135e9b34e8581b3209e5512ad59",
            "a507e77d945948d0af6d42155c953789",
            "798aa3d7d3744703a035926039986431",
            "a6a05dadb3744af69169c15bb5375404",
            "9a69f1928be64e73b40943d3b58fbc5b",
            "72eb2d9aed1c471ba9a30426fc2e92f9",
            "f45ad5792c3b4e38a91801fe13539abd",
            "f7d5d220762f44f8b1014b8ad2cb033a",
            "e7f83fdb288b49dbb2750d9a0d4f0a7e",
            "e3aa9d1f68ca4fefab6e8e06fb502c2e",
            "ff71e4217a1840358e476b4450a4570e",
            "c3991251e5a74ece9921362b9f285e3f",
            "43424a29d34e44d2a3b62e107c435d4a",
            "ae4d6dc420184ba5aba8d8843827365e",
            "fff299fe807d497ab687888804e6f4e9",
            "e717acddeab841e8b6cc26daf10d54bf",
            "6a787884280e468ca71ac49586d9abc2",
            "1e27ba9e2b394e11b89d43aa9d9283c6",
            "49f2bd3cf08a4f7d9226faa5bbd57e80",
            "4f5fb42824b841078c69e629397f0220",
            "73c6dd920e344033b891ae2c1539fadf",
            "7bab1728e9e34a05b64c9978997273a0",
            "553cf756baec414bbf90a3c86a5e638a",
            "04b8ab4d4d1d41c28b1dea17cfb27d99",
            "069b73d5d4c044a2bdcecf3937e55f1c",
            "e20c7351a08449708a7c83f8b79cf07b",
            "3005efc31f5c49a58eed4c3bbc679520"
          ]
        },
        "id": "QmUBVEnvCDJv",
        "outputId": "d6b10e75-424c-4e82-bde2-2f8e302cece8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ðŸ¦¥ Unsloth: Will patch your computer to enable 2x faster free finetuning.\n",
            "ðŸ¦¥ Unsloth Zoo will now patch everything to make training faster!\n",
            "==((====))==  Unsloth 2025.2.5: Fast Qwen2 patching. Transformers: 4.48.2.\n",
            "   \\\\   /|    GPU: Tesla T4. Max memory: 14.741 GB. Platform: Linux.\n",
            "O^O/ \\_/ \\    Torch: 2.5.1+cu124. CUDA: 7.5. CUDA Toolkit: 12.4. Triton: 3.1.0\n",
            "\\        /    Bfloat16 = FALSE. FA [Xformers = 0.0.29. FA2 = False]\n",
            " \"-____-\"     Free Apache license: http://github.com/unslothai/unsloth\n",
            "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5d0f87c0c912480598767c62c767722d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model.safetensors.index.json:   0%|          | 0.00/106k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "de8380f85d30411bb556020bcfa5cd35",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3537ca78cce54f86a39f9648751b2ec0",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model-00001-of-00002.safetensors:   0%|          | 0.00/5.00G [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b182215e45ed4a11a815a93f55931f11",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model-00002-of-00002.safetensors:   0%|          | 0.00/2.54G [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1ced1cbd196e415194772b15e1f8b52b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ea9bdc7e318e4d058b7096796239ef8e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/172 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6ec945d3e2b44f39b2603a2cc1ee7e49",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/4.72k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1dd148507d1744fc9659f15d5b5a4d92",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "vocab.json:   0%|          | 0.00/2.78M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7860351cd3e3448792762c271d7b6f89",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "merges.txt:   0%|          | 0.00/1.67M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1be5b64a6cdf442291cc1bd0881049fe",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "added_tokens.json:   0%|          | 0.00/605 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "72eb2d9aed1c471ba9a30426fc2e92f9",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/617 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6a787884280e468ca71ac49586d9abc2",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/11.4M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from unsloth import FastLanguageModel\n",
        "import torch\n",
        "max_seq_length = 2048 \n",
        "dtype = None \n",
        "load_in_4bit = True \n",
        "\n",
        "model, tokenizer = FastLanguageModel.from_pretrained(\n",
        "    model_name = \"unsloth/Qwen2.5-7B\",\n",
        "    max_seq_length = max_seq_length,\n",
        "    dtype = dtype,\n",
        "    load_in_4bit = load_in_4bit,\n",
        "\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6bZsfBuZDeCL",
        "outputId": "fca03569-2c79-455d-821d-bbe0743ed63f"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Unsloth 2025.2.5 patched 28 layers with 28 QKV layers, 28 O layers and 28 MLP layers.\n"
          ]
        }
      ],
      "source": [
        "model = FastLanguageModel.get_peft_model(\n",
        "    model,\n",
        "    r = 16, \n",
        "    target_modules = [\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\n",
        "                      \"gate_proj\", \"up_proj\", \"down_proj\",],\n",
        "    lora_alpha = 16,\n",
        "    lora_dropout = 0, \n",
        "    bias = \"none\",    \n",
        "    use_gradient_checkpointing = \"unsloth\", \n",
        "    random_state = 3407,\n",
        "    use_rslora = False,  \n",
        "    loftq_config = None, \n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 145,
          "referenced_widgets": [
            "fe0a19e76ebb4119a312d26a20bfbc0f",
            "e7359c7328ed455281f19d34e1332618",
            "498964adcf234de68488046a1faebb16",
            "18fb0fd2767f4088bce027e14d253ac4",
            "fd608a91465d44cd9010b51ce46d3614",
            "54d26e1b14814137858b4b5c4ebca01b",
            "f14f0091a2ea45f7a346b3b96e465f24",
            "d3de990b1765461c82254f165cea3a1e",
            "f3d83ad4092d4ea8905c5c3bdc25fda1",
            "74e2182e35f44b27892292922f94fa1c",
            "b41bec0ab93d4a66a58fff7663f427fb",
            "49b64d34c05f46afb2cb2b1545fe49ff",
            "3e78f6f4fe514dedba193c5c715b76cc",
            "349c26607a5a4a838f5d2c43e2c948ac",
            "95a05741c54b4efca664819d9b6ef039",
            "0f40d2ee48e04b208642533bcd91a8d7",
            "993ddeed5acf4e99933793384dfb2202",
            "8b73bf9336914e2da668b4fe7966dd3c",
            "cb2ce54a4d3241718faf1b351975acd8",
            "24366204484f40a4b894782db25c4723",
            "760a6208afcd4e27b46e20571344cf61",
            "43d4fdd091b641c3b6795926d15bb649",
            "96e3ab0de99847b3b99fb24c76866635",
            "97d79a1e92af4d80944f7937fa815317",
            "037b5ef0340f439bbf06e14d46848faf",
            "fea73cb5df63420baf0dd7f6b9d2e375",
            "174975f646fe49068704116693a51e6c",
            "0a9d2616da324904b6abea522d5fb074",
            "1e8208425ec144b88e3b0eb7a69b31b6",
            "f969fd9de7e54669b5454f8eb4abdcee",
            "88e598c554d04c349d4b8a64d5d79997",
            "4707787927304f9a9c9ab400c39469e8",
            "a07b281d10f0465e834aa1943469522f",
            "0a2fe853acdd4412bd2cc6e3d38929cb",
            "9a12804d8e59478ca114e7252020ff74",
            "594af361640c4173a09a5403b3c0d0e7",
            "3cba76b50c3e453e971444df582691ca",
            "f1e2cd0ff5574dcc9c18f5abe7dfa504",
            "281981569afe492a9c105029368260a3",
            "6760a0dd73f247b8be17f490bae7bf56",
            "5e0c03e0ee614bd5aa18fe7b25bdfb4e",
            "f8a21a01d5204efaa3d03c7ca3fddbee",
            "d00645f2802746afb5cd8574cf942c0b",
            "d311dbb600bd441ab7a196ab6c057ed3"
          ]
        },
        "id": "LjY75GoYUCB8",
        "outputId": "6e9266a4-efeb-41fa-afbf-07476eccd587"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "fe0a19e76ebb4119a312d26a20bfbc0f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "README.md:   0%|          | 0.00/353 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "49b64d34c05f46afb2cb2b1545fe49ff",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "train-00000-of-00001.parquet:   0%|          | 0.00/8.84M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "96e3ab0de99847b3b99fb24c76866635",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Generating train split:   0%|          | 0/16412 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0a2fe853acdd4412bd2cc6e3d38929cb",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/16412 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "alpaca_prompt = \"\"\"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n",
        "\n",
        "\n",
        "{}\n",
        "\n",
        "\n",
        "{}\n",
        "\n",
        "\n",
        "{}\"\"\"\n",
        "\n",
        "EOS_TOKEN = tokenizer.eos_token # Must add EOS_TOKEN\n",
        "def formatting_prompts_func(examples):\n",
        "    instructions = examples[\"instruction\"]\n",
        "    inputs       = examples[\"input\"]\n",
        "    outputs      = examples[\"output\"]\n",
        "    texts = []\n",
        "    for instruction, input, output in zip(instructions, inputs, outputs):\n",
        "\n",
        "        text = alpaca_prompt.format(instruction, input, output) + EOS_TOKEN\n",
        "        texts.append(text)\n",
        "    return { \"text\" : texts, }\n",
        "pass\n",
        "\n",
        "from datasets import load_dataset\n",
        "dataset = load_dataset(\"bpingua/medquad_cleaned\", split = \"train\")\n",
        "dataset = dataset.map(formatting_prompts_func, batched = True,)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "4ea633b725eb46f5993c70dc4308047a",
            "97daf3205b194185a97c5628cea98458",
            "22b63a23039c4b14b2a40fc012fc5467",
            "b5697f6dd9f64d6ba93377fac57f20c3",
            "0875fa2fc2d04d979528bccc5cad212b",
            "2219a524328b4c4aaa032d57955c39e4",
            "77baef931a954d2ea4cb145616107465",
            "03c07f55310d4aa5a516e4a37fce85c1",
            "7b554a477198406188e7ee420e5f362b",
            "7b9c22382f4b41c5b825c0598e8ac70b",
            "7c7e24ca04694418aee4cd0b7c41508b"
          ]
        },
        "id": "95_Nn-89DhsL",
        "outputId": "765b2ed0-6709-4cd1-b4b0-869c1b6d3da5"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4ea633b725eb46f5993c70dc4308047a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map (num_proc=2):   0%|          | 0/16412 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from trl import SFTTrainer\n",
        "from transformers import TrainingArguments\n",
        "from unsloth import is_bfloat16_supported\n",
        "\n",
        "trainer = SFTTrainer(\n",
        "    model = model,\n",
        "    tokenizer = tokenizer,\n",
        "    train_dataset = dataset,\n",
        "    dataset_text_field = \"text\",\n",
        "    max_seq_length = max_seq_length,\n",
        "    dataset_num_proc = 2,\n",
        "    packing = False, \n",
        "    args = TrainingArguments(\n",
        "        per_device_train_batch_size = 2,\n",
        "        gradient_accumulation_steps = 4,\n",
        "        warmup_steps = 5,\n",
        "        num_train_epochs = 1, \n",
        "        learning_rate = 2e-4,\n",
        "        fp16 = not is_bfloat16_supported(),\n",
        "        bf16 = is_bfloat16_supported(),\n",
        "        logging_steps = 1,\n",
        "        optim = \"adamw_8bit\",\n",
        "        weight_decay = 0.01,\n",
        "        lr_scheduler_type = \"linear\",\n",
        "        seed = 3407,\n",
        "        output_dir = \"outputs\",\n",
        "        report_to = \"wandb\", \n",
        "    ),\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2ejIt2xSNKKp",
        "outputId": "1e23a4e7-671a-4ca3-bab1-3a8f942abb48"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GPU = Tesla T4. Max memory = 14.748 GB.\n",
            "5.764 GB of memory reserved.\n"
          ]
        }
      ],
      "source": [
        "\n",
        "gpu_stats = torch.cuda.get_device_properties(0)\n",
        "start_gpu_memory = round(torch.cuda.max_memory_reserved() / 1024 / 1024 / 1024, 3)\n",
        "max_memory = round(gpu_stats.total_memory / 1024 / 1024 / 1024, 3)\n",
        "print(f\"GPU = {gpu_stats.name}. Max memory = {max_memory} GB.\")\n",
        "print(f\"{start_gpu_memory} GB of memory reserved.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 475
        },
        "id": "yqxqAZ7KJ4oL",
        "outputId": "5d7a7af2-3413-469f-b1cf-49a1c74ce85e"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "==((====))==  Unsloth - 2x faster free finetuning | Num GPUs = 1\n",
            "   \\\\   /|    Num examples = 16,412 | Num Epochs = 1\n",
            "O^O/ \\_/ \\    Batch size per device = 2 | Gradient Accumulation steps = 4\n",
            "\\        /    Total batch size = 8 | Total steps = 10\n",
            " \"-____-\"     Number of trainable parameters = 40,370,176\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='10' max='10' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [10/10 01:29, Epoch 0/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.978400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>1.085100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>1.270200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>1.075200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>1.197500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.936300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>1.042000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>1.147500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>0.914400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>1.037500</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "trainer_stats = trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pCqnaKmlO1U9",
        "outputId": "3005b362-2b86-468a-8f28-8effd9208566"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "462.3942 seconds used for training.\n",
            "7.71 minutes used for training.\n",
            "Peak reserved memory = 7.893 GB.\n",
            "Peak reserved memory for training = 2.129 GB.\n",
            "Peak reserved memory % of max memory = 53.519 %.\n",
            "Peak reserved memory for training % of max memory = 14.436 %.\n"
          ]
        }
      ],
      "source": [
        "\n",
        "used_memory = round(torch.cuda.max_memory_reserved() / 1024 / 1024 / 1024, 3)\n",
        "used_memory_for_lora = round(used_memory - start_gpu_memory, 3)\n",
        "used_percentage = round(used_memory / max_memory * 100, 3)\n",
        "lora_percentage = round(used_memory_for_lora / max_memory * 100, 3)\n",
        "print(f\"{trainer_stats.metrics['train_runtime']} seconds used for training.\")\n",
        "print(\n",
        "    f\"{round(trainer_stats.metrics['train_runtime']/60, 2)} minutes used for training.\"\n",
        ")\n",
        "print(f\"Peak reserved memory = {used_memory} GB.\")\n",
        "print(f\"Peak reserved memory for training = {used_memory_for_lora} GB.\")\n",
        "print(f\"Peak reserved memory % of max memory = {used_percentage} %.\")\n",
        "print(f\"Peak reserved memory for training % of max memory = {lora_percentage} %.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kR3gIAX-SM2q",
        "outputId": "4395a6c9-ee57-4f5f-84ba-a60fe5b915ae"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\\n\\n### Instruction:\\nContinue the fibonnaci sequence.\\n\\n### Input:\\n1, 1, 2, 3, 5, 8\\n\\n### Response:\\n13, 21, 34, 55, 89, 144, 233, 377, 610, 987, 1597, 2584, 4181, 6']"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\n",
        "FastLanguageModel.for_inference(model) \n",
        "inputs = tokenizer(\n",
        "[\n",
        "    alpaca_prompt.format(\n",
        "        \"Answer this question truthfully\", \n",
        "        \"What causes Glaucoma ?\", \n",
        "        \"\", \n",
        "    )\n",
        "], return_tensors = \"pt\").to(\"cuda\")\n",
        "\n",
        "outputs = model.generate(**inputs, max_new_tokens = 64, use_cache = True)\n",
        "tokenizer.batch_decode(outputs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-X1TpAqCVIQx"
      },
      "outputs": [],
      "source": [
        "torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 469,
          "referenced_widgets": [
            "e0ba66a342b449938e73483521f0f7c1",
            "143a78ea8e6d4d59a7d288beb524bdfc",
            "437ffaaa85de4f1fa0576ab473672e8e",
            "f0fbff417506458a96ce22c33d15dde1",
            "c54386a78544433493c61c65160f5ea1",
            "eb644af666ce4dabb725a10666b1eaf8",
            "bf28671384794decbd2583f0a3d73020",
            "ea740c4087e5464eb0812b7537095592",
            "93a3fcfa707a4afa8940d9b1df6115bb",
            "45a684299fb942d7b467b22d586b8712",
            "f9f74fe788e64a74b21bb451735d82d8",
            "238f079b48a540159964f0228eb8f03a",
            "285cf6921b5245438cbc3ea2c58dedcb",
            "8aa31cb94b2b4e5eaef2a05ee04b8d15",
            "12a59caccf4f4f43983eebf0a6eb438c",
            "913c94d0bc334e1b98baccd2943a0c06",
            "dd5eb32fbeba4cc78f9b0178aadbaef6",
            "431be8b4be88471e8e2f919c6a77b10a",
            "67576414db6d45d5bac8464f03115c30",
            "9f88d646533d45e391d0560cc2ad2e12",
            "62c719840ed3464cbd06353847a3a34f",
            "1ac1901e45634581882651cf00b4fa10",
            "bbc10c1232ee4e2298be7563b52b6467",
            "224ad02d6c914907b2c737639c384854",
            "a6307f3b5c8142c3a5bac76b98614e5a",
            "2e04cff2811b41a0a4f3534a6262b5ba",
            "61043298d53140aa925ceb6f3e552546",
            "1d818ab8921e47599fea3d09b6e3fe83",
            "f6dbaddc057c43b48c2fe483ae9087be",
            "4f2109c2c3dc4d0b9f64d8dd0993fd4b",
            "d10109eb07de4cc29d634ce6488b4b01",
            "7dc95dc07eaf4529834693a17e66c071",
            "8d7c4a18f8684c55b7c7b27de67bf41f",
            "d2010f17a3f84cb8ac14641ed9fb7920",
            "156b38b6251c4b6797c8fae32ded2e65",
            "57617815de254f6d99a7e7b8907be4d5",
            "598b38ef5a7b44a798b8c7661acf94eb",
            "38947b7eaff747ee9772c3c21098ebf1",
            "890363667ac1476a807f71634e8d59a1",
            "f39cb7d40d964bde861a2b8e89168e79",
            "e68f0de8008847a88d1a0789adc6afa9",
            "5cda65b9dd11468aa46826040db38b7d",
            "a90a5c9764354d33ab97e5f0912287a1",
            "dae2ca02f66346989c3063fc05f4afdb",
            "19c8d96ea519489ca5c53d73b1f9f00e",
            "cf95a344d66d49c39e33b485f3d2651f",
            "d3b455ca571c4caa8d03ba8ff4d74309",
            "ed40641cb7d14ef9973afa317363d4b4",
            "4119fa4cc2d2433cab9a37194769ae29",
            "4a59dfa2aa2d4660a8ce515d1be007cf",
            "02ee983a8a0148fb9e2469e0037f7c6a",
            "8b9fa258d71d4feeab9fd4e3f5db54cd",
            "62f71484646c404687719ead859ed7af",
            "6cff9f668dc04236b40159d80dfa84cd",
            "e4bb98a583f8400c9b3bd717e7e118ed",
            "518d9ae54a7c44659f24c1e31b71c00a",
            "7ea24717831b41d5a2060b3ad9fb5bf8",
            "c655e670418d409d8d0f02a03f6b7b3f",
            "bb31ad85004842cdbea809084d29d0de",
            "fa6c574c29a44b84981eaefc7c663527",
            "b2179c3e5273481eb3f7f61f34976eaf",
            "27899896ca3047fd86d7f665ddcc1171",
            "c40161b9d53d49af9f3b62611bb238db",
            "2bb088b28bc14a3cb42293d6f3b62637",
            "a01e04c3e6a948099b124d8814f8b482",
            "bcb64c5dec854374b3b427096ca61b0d",
            "8ccb03113f834ba7860c2dc5a0fe1667",
            "4c7424bfe4544813b7175207fd3942fb",
            "c22db37afe0143acb83d7d4d847475a8",
            "4b2f2530093a473f90f63ddc16479b73",
            "6d6118664c104ea28cb93c49acfd5bda",
            "3f2b587f7a7540088a9cdff8d932f899",
            "7227b43c6b1947cf930a9fe8f8d762a8",
            "3c6a333bd4f1411e9cb6d406dd33c160",
            "0d42a4439b85446fab0f16e4d144a53a",
            "d4e8fca8188f498eab89fb26104a2823",
            "5b485d4d02ee40ac8d1283bc2ab74165"
          ]
        },
        "id": "iHjt_SMYsd3P",
        "outputId": "69c1ee99-4f14-433f-c339-0669c55d463e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Unsloth: Merging 4bit and LoRA weights to 4bit...\n",
            "This might take 5 minutes...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/peft/tuners/lora/bnb.py:355: UserWarning: Merge lora module to 4-bit linear may get different generations due to rounding errors.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Done.\n",
            "Unsloth: Saving tokenizer... Done.\n",
            "Unsloth: Saving model... This might take 10 minutes for Llama-7b... Done.\n",
            "Unsloth: Merging 4bit and LoRA weights to 4bit...\n",
            "This might take 5 minutes...\n",
            "Done.\n",
            "Unsloth: Saving 4bit Bitsandbytes model. Please wait...\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e0ba66a342b449938e73483521f0f7c1",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "README.md:   0%|          | 0.00/590 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "238f079b48a540159964f0228eb8f03a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/2 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "bbc10c1232ee4e2298be7563b52b6467",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model-00002-of-00002.safetensors:   0%|          | 0.00/2.54G [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d2010f17a3f84cb8ac14641ed9fb7920",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model-00001-of-00002.safetensors:   0%|          | 0.00/5.00G [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "19c8d96ea519489ca5c53d73b1f9f00e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "README.md:   0%|          | 0.00/596 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "518d9ae54a7c44659f24c1e31b71c00a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8ccb03113f834ba7860c2dc5a0fe1667",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/11.4M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved merged_4bit model to https://huggingface.co/bpingua/Qwen2.5-7B-Medquad\n"
          ]
        }
      ],
      "source": [
        "\n",
        "if True: model.save_pretrained_merged(\"Qwen2.5-7B-Medquad-16bit\", tokenizer, save_method = \"merged_16bit\",)\n",
        "if True: model.push_to_hub_merged(\"bpingua/Qwen2.5-7B-Medquad-16bit\", tokenizer, save_method = \"merged_16bit\", token = \"\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
