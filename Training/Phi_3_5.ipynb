{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t7PeU0voNpAJ"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install --no-deps bitsandbytes accelerate xformers==0.0.29.post3 peft trl==0.15.2 triton cut_cross_entropy unsloth_zoo\n",
        "!pip install sentencepiece protobuf datasets huggingface_hub hf_transfer\n",
        "!pip install --no-deps unsloth"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 380,
          "referenced_widgets": [
            "48232d45893e4f69adc2e9676968a192",
            "6521e581b8ae4346aa156c44e599a818",
            "f89d7848009f4eb090105ef73234ecf3",
            "fcdc8479df314b469de9fb1d7f4c949e",
            "f98494a90a4a4791888a1cb0af27db70",
            "85fad2ce92c7463da785eb760f21ad32",
            "34e659f5c280437097bd8e8919692390",
            "371a28c6e9da4297a0c8f03c63f9f4d4",
            "a724e19f70b842b78bf209ee3939cfc2",
            "f0210a48559948dc8705e37df3f1e991",
            "76ac9967082f412293f80c273662de23",
            "60c976db136548ec9082f0f375820748",
            "a1548c1e7ecc4e6f9d3b56d8daeb0f3f",
            "d246aeb1271048ee84546c201094805e",
            "6bae05f4dccb4ba199e27d00a9cd66f7",
            "0a2c8d0d4d6346d48f86d5752d99070b",
            "b1da25aa15114f458afa758796e2edbe",
            "ece69a6192b7460abb85e96a8eceb0ab",
            "99e60edf35c947e7a2b89ae8382c8a76",
            "3f09e4d366cc43eaa1b2f1734e9f8f5f",
            "a092f94a80664116b0965ad2a1fa1c39",
            "bb65fcbb526d435aa108414fb15dfc4f",
            "b046ca0889274216bf13ca208667aa9b",
            "ef2c9bf50d4948a3b859693bbb3eb2da",
            "353d790bcd3349d18df6c25214c5c75e",
            "b775c0678c0a4fe4986292ee64a70c58",
            "fc9617f4b5434b9c865980813f53c505",
            "854f507df3ed4ebbb0fa2694e5b76e91",
            "f2efc16436714c199a53bb61f15bd369",
            "427925775af4452195a075370fbb30ac",
            "dc225b30bdee421d9b6819d5192434da",
            "ad2d55913e254966b4e8881573bb7e01",
            "6f70d733d3b449e0becc0da2d62d5292",
            "4011b69b6f734d66adc8e915bfb661de",
            "2121877bab874089999434bb03a0a3dd",
            "1299c356ca1d4b0db5a50238b1b8a340",
            "0e9016592622456eb0e1f07f17133a97",
            "b8a6ebda9cf5406582585c5b3b08a1a5",
            "a674bf6d50c24b57aa06fcf04f668b8a",
            "53075e14a5d74564bb42f2174a90029d",
            "4ec407e90ebc436fb750d15b31909381",
            "4aaf4d43d8864ce4a921dad194650d25",
            "54be1396b9ee41f79d23ef46dbe8e6c6",
            "c121ab40bf0043539ab0284ab12836dd",
            "6538ba1512af43ed8ba05b0201a87797",
            "823ea747446145639c488480e8133b2a",
            "49378608e00e4d349980121eff09fea8",
            "37ee0a1f1d13485e85dd6943c58c7ff9",
            "3bafb768e3434082a4e1b70ebaf89fd9",
            "ce489c3f67544b7c921f2a398ded63bc",
            "08ac730b0e8e4f319eddb4b50f0d5606",
            "a7a623d898cf41e8af1c29c46e06c2c6",
            "09be4ac5b8274e51bcb8aeccab516bd8",
            "911b461641cb48ffa4e9b412794feb6f",
            "470e71d43d054964ba64825242e84fd2",
            "ba3a098cb3904fd2a7ed43e9cea6bc56",
            "a6bfefb6e11e48758b1727ce98c9a070",
            "4779a21eae694cfd8907cb1b561dcb88",
            "146d15fffe7b4b0d9056c9be98f7e887",
            "b70491dd41da4868a5a2a40d8a4d8875",
            "a9a954a3123440d49672bc5bd26fa591",
            "5f39c7edfcf14fd882a39af80931a253",
            "3dc03e8cd27140dea3831e3f43266c05",
            "c4ae9de01c5e4b93ab875ed16327a4d4",
            "70670b47eda045d9ab53826df82431d4",
            "063d28a15d974ce087a9103c8106fce0",
            "c42aa04e34ac482086b22e99c2eb0a8b",
            "e0b3338bd6f8423ab9f6b7879bae414e",
            "3c3543bf676b4a849cd951a345a3a53a",
            "7ebb7edaecd14009820ba30cdb6c0d0b",
            "9f3454f5bba54ecdb428d03176d56c43",
            "37e4a6f46ac747b8a546a35e42e4651e",
            "aebdef21f12948e1accd183f746cfa9f",
            "c026c4dd43ed4f6a9a740ca6a6f116c3",
            "af725996da644701ae06bccd57b6a5aa",
            "bda0e169f9d848be9c4f99437bad1890",
            "670f172bae45439a86a04447df46e7ef"
          ]
        },
        "id": "QmUBVEnvCDJv",
        "outputId": "0e7aa1ff-0bda-457c-e028-e38f4e57ced1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ðŸ¦¥ Unsloth: Will patch your computer to enable 2x faster free finetuning.\n",
            "ðŸ¦¥ Unsloth Zoo will now patch everything to make training faster!\n",
            "==((====))==  Unsloth 2025.2.9: Fast Llama patching. Transformers: 4.48.2.\n",
            "   \\\\   /|    GPU: Tesla T4. Max memory: 14.741 GB. Platform: Linux.\n",
            "O^O/ \\_/ \\    Torch: 2.5.1+cu124. CUDA: 7.5. CUDA Toolkit: 12.4. Triton: 3.1.0\n",
            "\\        /    Bfloat16 = FALSE. FA [Xformers = 0.0.29. FA2 = False]\n",
            " \"-____-\"     Free Apache license: http://github.com/unslothai/unsloth\n",
            "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "48232d45893e4f69adc2e9676968a192",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/2.26G [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "60c976db136548ec9082f0f375820748",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/140 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b046ca0889274216bf13ca208667aa9b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/3.37k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4011b69b6f734d66adc8e915bfb661de",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer.model:   0%|          | 0.00/500k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6538ba1512af43ed8ba05b0201a87797",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "added_tokens.json:   0%|          | 0.00/293 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ba3a098cb3904fd2a7ed43e9cea6bc56",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/571 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c42aa04e34ac482086b22e99c2eb0a8b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/1.84M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from unsloth import FastLanguageModel\n",
        "import torch\n",
        "max_seq_length = 2048\n",
        "dtype = None\n",
        "load_in_4bit = True\n",
        "model, tokenizer = FastLanguageModel.from_pretrained(\n",
        "    model_name = \"unsloth/Phi-3.5-mini-instruct\",\n",
        "    max_seq_length = max_seq_length,\n",
        "    dtype = dtype,\n",
        "    load_in_4bit = load_in_4bit,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6bZsfBuZDeCL",
        "outputId": "1e2f0b41-26ef-4854-a59a-a4b36fd09754"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Unsloth 2025.2.9 patched 32 layers with 32 QKV layers, 32 O layers and 32 MLP layers.\n"
          ]
        }
      ],
      "source": [
        "model = FastLanguageModel.get_peft_model(\n",
        "    model,\n",
        "    r = 16, \n",
        "    target_modules = [\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\n",
        "                      \"gate_proj\", \"up_proj\", \"down_proj\",],\n",
        "    lora_alpha = 16,\n",
        "    lora_dropout = 0, \n",
        "    bias = \"none\",    \n",
        "    use_gradient_checkpointing = \"unsloth\", \n",
        "    random_state = 3407,\n",
        "    use_rslora = False, \n",
        "    loftq_config = None, \n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 145,
          "referenced_widgets": [
            "184d2913f39d48f0b764fd33639f788d",
            "ce346e13e8bd4a55a9a638838aadf81d",
            "198586065d9c41cd904a9f60106ee073",
            "d11e96a845c844569a56eda7167abbbc",
            "e9fe306166f04daba43064e9bf858edc",
            "b8b5775c0f354903b25fcc4ab0ded84d",
            "cb54ac7e6d5243f8961c206e34242013",
            "507d705546234a4caac1a9e48bf0264a",
            "24f118e020d1494790d69b58dd67b6e1",
            "26294b82d3bb4347af872180611029df",
            "99879a7d819e4f2e9a69c541bc0b2422",
            "704c1a54aff64435a3a01cb1f823db92",
            "991baf5ce8cb46d2ba4d61f11bb72490",
            "6d5d87b576344aa995676e3b3e36a5ce",
            "8107ea19363b4b94b9fb6c352daf226b",
            "f4d56c0e3d6f4bbf907e329df2aeaa2e",
            "10fb365187574fcb9af8186898b1c82a",
            "622f221c755e41b2995d6c6aae4e9151",
            "66762527f591414d87a0084baaf10eec",
            "c31b3fd49deb4d8ba867cd631fa01cc2",
            "9ae5b0e611a945b2a6eb66f1ae44de94",
            "7fad56e26c9f4729ae5a37e8444c449f",
            "d5af3fd0b8ed490eabc448b07acee69c",
            "c08f0f9e68734f4daf24280a4ddd42cd",
            "19dc28a588a74e94a14e9e286a5801d8",
            "615cc36f93dc4508b134bc175e5f2438",
            "4acb84b5305d4c59b3a203327f10d21a",
            "29d26165cb1943c7bd24b9f90dd71527",
            "24455c82988c4e02b2b3f8bb43e6cac7",
            "d2028e48de5341a3816f5a4214bac6b4",
            "5f07cf273bc74de58601bc749c557c48",
            "f94f9a27b5bf49b59b8554bda52b2f6e",
            "78911e22bcdb456e9c2466654e9df626",
            "b63d846481f648bf84cc451e16cda73a",
            "013572e0e24844c6b04e1c1069aad515",
            "bd7074df03da485b89d4edc7bc3cdb27",
            "2ce20459003342dbbcbd6ba0726bed4e",
            "a5c0fbf839d0411791cd35b689a49671",
            "69154520506d4de6a7a487d8835286b4",
            "c507d45f0ddb4ca4a104d1909e9dff6b",
            "61add0ef4979450eaa63cd6c49bbf9ad",
            "0cc6bada91a64d769be877565d6c72d7",
            "50b45fe24dff4085b15732bb71c8e87d",
            "2eda31320a544fc98db82e0d40223973"
          ]
        },
        "collapsed": true,
        "id": "Edrn7Rxmojtu",
        "outputId": "a7433417-4e43-4e4a-bc71-166570e67aa1"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "184d2913f39d48f0b764fd33639f788d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "README.md:   0%|          | 0.00/353 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "704c1a54aff64435a3a01cb1f823db92",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "train-00000-of-00001.parquet:   0%|          | 0.00/8.84M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d5af3fd0b8ed490eabc448b07acee69c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Generating train split:   0%|          | 0/16407 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b63d846481f648bf84cc451e16cda73a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/16407 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from unsloth.chat_templates import get_chat_template\n",
        "\n",
        "tokenizer = get_chat_template(\n",
        "    tokenizer,\n",
        "    chat_template = \"phi-3\", \n",
        "    mapping = {\"role\" : \"from\", \"content\" : \"value\", \"user\" : \"human\", \"assistant\" : \"gpt\"}, \n",
        ")\n",
        "\n",
        "def formatting_prompts_func(examples):\n",
        "    convos = examples[\"conversations\"]\n",
        "    texts = [tokenizer.apply_chat_template(convo, tokenize = False, add_generation_prompt = False) for convo in convos]\n",
        "    return { \"text\" : texts, }\n",
        "pass\n",
        "\n",
        "from datasets import load_dataset\n",
        "dataset = load_dataset(\"bpingua/medquad_sharegpt_cleaned\", split = \"train\")\n",
        "dataset = dataset.map(formatting_prompts_func, batched = True,)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "U5iEWrUkevpE",
        "outputId": "08b4375f-fc88-4b3c-ec56-08da8aeb336d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<|user|>\n",
            "What is (are) Glaucoma ?<|end|>\n",
            "<|assistant|>\n",
            "The optic nerve is a bundle of more than 1 million nerve fibers. It connects the retina to the brain.<|end|>\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(dataset[5][\"text\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "Bwux6QMwTI9s",
        "outputId": "1919cae4-8dbf-4898-cb88-4665ba5e986e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<|user|>\n",
            "What is (are) Medicare and Continuing Care ?<|end|>\n",
            "<|assistant|>\n",
            "Medicare Part A is hospital insurance that helps cover inpatient care in hospitals. Part A also helps cover skilled nursing facility care for a limited period of time, hospice care, and home health care, if you meet certain conditions. Most people don't have to pay a monthly premium for Medicare Part A when they turn age 65 because they or a spouse paid Medicare taxes while they were working. If a person is hospitalized, Medicare helps pay for the following services. - Care - general nursing - Room - semiprivate room  - Hospital services - meals, most services and supplies Care - general nursing Room - semiprivate room Hospital services - meals, most services and supplies If a person is hospitalized, Medicare does NOT pay for the following services. - Care - private-duty nursing  - Room - private room (unless medically necessary) - Hospital services - television and telephone Care - private-duty nursing Room - private room (unless medically necessary) Hospital services - television and telephone For important information about Medicare Part A, visit http://www.medicare.gov to view or print copies of \"Your Medicare Benefits\" or \"Medicare & You.\" (Under \"Search Tools,\" select \"Find a Medicare Publication.\")<|end|>\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(dataset[123][\"text\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 113,
          "referenced_widgets": [
            "2dff7305c7bf4949b138a9c28cc835bb",
            "db541225f7c843998f58f56809d17742",
            "acc285f46d58482b9444f5df21d724e9",
            "09fdfa7828774dddb65a60ff361e13d1",
            "661bb015447f40339b4f2cd6a19c1e30",
            "cc7b571f8d3749eeae4b09907a8b3332",
            "8dbe5623d6014dcaad05b09d90ef4c94",
            "70d7bdba41b5452eb9118a5e865af9ef",
            "b32fbdf9b1a143d0b9ae7e23b91ab068",
            "e247deaee24f46a9893be7656f0190e7",
            "b83aec92967e432b90118be2b07f9d8e",
            "7e95064c84634eb88562eb13b1b8521c",
            "e078b6fa9cfd4abbb9bec5d150e1a3ec",
            "5b97c5adfe1f4a08b8a9fe515a51cd67",
            "6b250bcac9924e33a1729f08fab8f26a",
            "7f96392bf7ea467b840e3e99d01894d2",
            "4acf9eb53cf34dfb946d081c47e75fb4",
            "148586669ef34b0db477ce602f7ab827",
            "112bbd6aff6149e6ac2782169648a586",
            "7d489c8ee0ce4ecc8d910688fc6b28c4",
            "0d47833ae9f546dba28cbd9d7bffeb4e",
            "56bf7a141f6945b6ac9077f1d272db51",
            "97d59be0d4f34d39ade4aa76be3e4bca",
            "9565102993eb4bdca39eb25d254e07dd",
            "2536472ddd84486aa5ac00cc970cd035",
            "05b34473e3bb4f46835640515efedaf6",
            "c963604837184c80af9a7dad07318dc1",
            "169341da540a44d880292a0996ce8489",
            "f45e7fb05ea74b9ba01ef7b07b465649",
            "2df24484d3434f549638a740df6c110f",
            "5b53ac49f3b046f9b6cb43818f28a888",
            "909b702e3c32435eac3b91ce35816cc2",
            "8ec2ab7badd8458c9e1b32eec645f6fb"
          ]
        },
        "id": "95_Nn-89DhsL",
        "outputId": "5bc4f031-8ae9-4221-b44f-c4096640e7e5"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2dff7305c7bf4949b138a9c28cc835bb",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Applying chat template to train dataset (num_proc=2):   0%|          | 0/16407 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7e95064c84634eb88562eb13b1b8521c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Tokenizing train dataset (num_proc=2):   0%|          | 0/16407 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "97d59be0d4f34d39ade4aa76be3e4bca",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Tokenizing train dataset (num_proc=2):   0%|          | 0/16407 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from trl import SFTTrainer\n",
        "from transformers import TrainingArguments\n",
        "from unsloth import is_bfloat16_supported\n",
        "\n",
        "trainer = SFTTrainer(\n",
        "    model = model,\n",
        "    tokenizer = tokenizer,\n",
        "    train_dataset = dataset,\n",
        "    dataset_text_field = \"text\",\n",
        "    max_seq_length = max_seq_length,\n",
        "    dataset_num_proc = 2,\n",
        "    packing = False,\n",
        "    args = TrainingArguments(\n",
        "        per_device_train_batch_size = 2,\n",
        "        gradient_accumulation_steps = 4,\n",
        "        warmup_steps = 5,\n",
        "        num_train_epochs=1,\n",
        "        learning_rate = 2e-4,\n",
        "        fp16 = not is_bfloat16_supported(),\n",
        "        bf16 = is_bfloat16_supported(),\n",
        "        logging_steps = 1,\n",
        "        optim = \"adamw_8bit\",\n",
        "        weight_decay = 0.01,\n",
        "        lr_scheduler_type = \"linear\",\n",
        "        seed = 3407,\n",
        "        output_dir = \"outputs\",\n",
        "        report_to = \"wandb\", \n",
        "    ),\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2ejIt2xSNKKp",
        "outputId": "b601900f-47fc-4e94-f0b7-654b6992fdd2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GPU = Tesla T4. Max memory = 14.741 GB.\n",
            "2.236 GB of memory reserved.\n"
          ]
        }
      ],
      "source": [
        "\n",
        "gpu_stats = torch.cuda.get_device_properties(0)\n",
        "start_gpu_memory = round(torch.cuda.max_memory_reserved() / 1024 / 1024 / 1024, 3)\n",
        "max_memory = round(gpu_stats.total_memory / 1024 / 1024 / 1024, 3)\n",
        "print(f\"GPU = {gpu_stats.name}. Max memory = {max_memory} GB.\")\n",
        "print(f\"{start_gpu_memory} GB of memory reserved.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 476
        },
        "id": "yqxqAZ7KJ4oL",
        "outputId": "24aef7ad-ac54-4ea0-ce29-42f08107b128"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "==((====))==  Unsloth - 2x faster free finetuning | Num GPUs = 1\n",
            "   \\\\   /|    Num examples = 16,407 | Num Epochs = 1\n",
            "O^O/ \\_/ \\    Batch size per device = 2 | Gradient Accumulation steps = 4\n",
            "\\        /    Total batch size = 8 | Total steps = 2,051\n",
            " \"-____-\"     Number of trainable parameters = 29,884,416\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='12' max='2051' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [  12/2051 01:05 < 3:42:41, 0.15 it/s, Epoch 0.01/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>1.612800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>1.717300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>1.447700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>1.492800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>1.527700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>1.551400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>1.335900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>1.569300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>1.380400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>1.304000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "trainer_stats = trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pCqnaKmlO1U9",
        "outputId": "af1a8791-2548-40a6-ff4d-4e29cd825c5e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "103.0339 seconds used for training.\n",
            "1.72 minutes used for training.\n",
            "Peak reserved memory = 2.943 GB.\n",
            "Peak reserved memory for training = 0.705 GB.\n",
            "Peak reserved memory % of max memory = 19.965 %.\n",
            "Peak reserved memory for training % of max memory = 4.783 %.\n"
          ]
        }
      ],
      "source": [
        "used_memory = round(torch.cuda.max_memory_reserved() / 1024 / 1024 / 1024, 3)\n",
        "used_memory_for_lora = round(used_memory - start_gpu_memory, 3)\n",
        "used_percentage = round(used_memory / max_memory * 100, 3)\n",
        "lora_percentage = round(used_memory_for_lora / max_memory * 100, 3)\n",
        "print(f\"{trainer_stats.metrics['train_runtime']} seconds used for training.\")\n",
        "print(\n",
        "    f\"{round(trainer_stats.metrics['train_runtime']/60, 2)} minutes used for training.\"\n",
        ")\n",
        "print(f\"Peak reserved memory = {used_memory} GB.\")\n",
        "print(f\"Peak reserved memory for training = {used_memory_for_lora} GB.\")\n",
        "print(f\"Peak reserved memory % of max memory = {used_percentage} %.\")\n",
        "print(f\"Peak reserved memory for training % of max memory = {lora_percentage} %.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kR3gIAX-SM2q",
        "outputId": "690a83b8-dcd5-4916-c13d-31296c95da21"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "['<|user|> What are the symptoms of Glaucoma ?<|end|><|assistant|> Glaucoma is a group of eye conditions that damage the optic nerve, which is vital for good vision. The damage is often caused by abnormally high pressure in your eye.\\n\\nSymptoms of Glaucoma:\\n\\n1. Loss of peripheral vision: The']"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from unsloth.chat_templates import get_chat_template\n",
        "tokenizer = get_chat_template(\n",
        "    tokenizer,\n",
        "    chat_template = \"phi-3\",\n",
        "    mapping = {\"role\" : \"from\", \"content\" : \"value\", \"user\" : \"human\", \"assistant\" : \"gpt\"}, \n",
        ")\n",
        "\n",
        "FastLanguageModel.for_inference(model) \n",
        "\n",
        "messages = [\n",
        "    {\"from\": \"human\", \"value\": \"What are the symptoms of Glaucoma ?\"},\n",
        "]\n",
        "inputs = tokenizer.apply_chat_template(\n",
        "    messages,\n",
        "    tokenize = True,\n",
        "    add_generation_prompt = True, \n",
        "    return_tensors = \"pt\",\n",
        ").to(\"cuda\")\n",
        "\n",
        "outputs = model.generate(input_ids = inputs, max_new_tokens = 64, use_cache = True)\n",
        "tokenizer.batch_decode(outputs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tfh0narRPw4L"
      },
      "outputs": [],
      "source": [
        "torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 353,
          "referenced_widgets": [
            "50eb59e7f67e42898a5e42d42e17b267",
            "f3d20bf4be374fbfa18ece91c54fa53c",
            "984facf2517b4197bd67bf3c82077c59",
            "d43b11eb98b54efdaf395b964d74f44f",
            "8869d8571be84c0680a84de96adc80a3",
            "3e4767a501064d5cb81c23005b403b26",
            "e45205151d1a4ec6a46c4e64006b5463",
            "aea0a66b8fa7479ea78ce31b552aac9e",
            "9bbe06ba40104df69d1206516de70207",
            "d41f156ade204d2d8f3c17d2cc82d3e6",
            "bf8b006cdb854ef480f8dde040b8a127",
            "4b44bf3f26fa43c18278e638b49b0fa1",
            "10783819fd8a4a9983969bc93ac16933",
            "1919cac96b314988ac982a5c34fbab7a",
            "4d23e5e1218f41889c1702d3473ebd39",
            "89477f358a1d4d66a5d587d3f78f40c1",
            "daaf92d66c9347ac94f959f1819b153e",
            "93b04c71357b4c67813ea071f4d5b7e1",
            "4e9e246a728b4be587834b54207db838",
            "2b0a88fb559b41d98ba4e2440876312b",
            "5b17c17f9817409a928286392d72b1d4",
            "9b0014f05dca49a680d5c2473e548a33",
            "ee1998c0072c4d219b08f9e80a1f4a05",
            "269f537c2a5347e89b4d5fd07b17d61e",
            "e56a21c83d0e4da0bdd1463d6d6db95f",
            "2d1ac3ddd4254e71beb7837f8f584366",
            "0771c6b103544a4e911e920618dd69f7",
            "9efb4666a4ea45d68d555491c6816b51",
            "82bfa284343d4ca2addf2a3370536087",
            "7dcca364133d425a81f76c61d82f8e95",
            "e2a5f65f087943c281484c9cb5745a0b",
            "b0bd16f0984740eb9a6afb3df14c0e25",
            "239f7078bc3c441f9c52dc0533b14146",
            "20526972bc454d77951bbebcf98762eb",
            "d8f85060319946d8971d9e27c2653ada",
            "aca82d0f56ad42ae8597ad2d2b8953e4",
            "6dca86221d404cf6a6712e577fab90c9",
            "1a1f4f2ff747411790d4209e1dd0db76",
            "959773bca4fd495ba38c74878adc5750",
            "6cd8bce123ca451fb5da9d94835e7898",
            "ad471217a3524edfa5550b4fae945657",
            "09115067c0da42acb9174a3e07a253be",
            "4e52d57a644549f4949f2e2511e8a2a3",
            "b209b5c577234e80a0ddd6010eabed30"
          ]
        },
        "id": "nVCXnG4fPwwn",
        "outputId": "86e17b56-8ba2-4413-c64d-a8fc437f0365"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Unsloth: Merging 4bit and LoRA weights to 4bit...\n",
            "This might take 5 minutes...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/peft/tuners/lora/bnb.py:355: UserWarning: Merge lora module to 4-bit linear may get different generations due to rounding errors.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Done.\n",
            "Unsloth: Saving tokenizer... Done.\n",
            "Unsloth: Saving model... This might take 10 minutes for Llama-7b... Done.\n",
            "Unsloth: Merging 4bit and LoRA weights to 4bit...\n",
            "This might take 5 minutes...\n",
            "Done.\n",
            "Unsloth: Saving 4bit Bitsandbytes model. Please wait...\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "50eb59e7f67e42898a5e42d42e17b267",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "README.md:   0%|          | 0.00/596 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4b44bf3f26fa43c18278e638b49b0fa1",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ee1998c0072c4d219b08f9e80a1f4a05",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/2.26G [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "20526972bc454d77951bbebcf98762eb",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "README.md:   0%|          | 0.00/602 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved merged_4bit model to https://huggingface.co/bpingua/Phi-3.5-mini-instruct-Medquad\n"
          ]
        }
      ],
      "source": [
        "\n",
        "if True: model.save_pretrained_merged(\"Phi-3.5-mini-instruct-Medquad\", tokenizer, save_method = \"merged_16bit\",)\n",
        "if True: model.push_to_hub_merged(\"bpingua/Phi-3.5-mini-instruct-Medquad\", tokenizer, save_method = \"merged_16bit\", token = \"\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
